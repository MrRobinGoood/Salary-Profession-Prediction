{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e988fb-e654-45ef-8126-85b8a1c40b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow-gpu keras scikit-learn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9af9210-0e25-4fc4-83d3-dc690b4a2059",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Путь к загружаемой модели\n",
    "model_path = '/home/jupyter/datasphere/project/model.h5'\n",
    "\n",
    "# Загрузка модели\n",
    "model = load_model(model_path)\n",
    "print(f\"Модель успешно загружена из файла {model_path}\")\n",
    "\n",
    "# Загрузка нового файла с данными (например, в формате CSV)\n",
    "new_data_path = '/home/jupyter/datasphere/project/TEST_RES.csv'  # Укажите путь к вашему новому файлу\n",
    "new_df = pd.read_csv(new_data_path)\n",
    "\n",
    "# Предполагается, что в новом файле есть столбцы 'achievements_modified' и 'demands'\n",
    "# Создание текстовых данных для предсказания\n",
    "new_text_data = []\n",
    "for _, row in new_df.iterrows():\n",
    "    combined_text = f\"{row['achievements_modified']} {row['demands']}\"\n",
    "    new_text_data.append(combined_text)\n",
    "\n",
    "# Токенизация новых текстов\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(new_text_data)  # Обучить токенизатор на новых данных\n",
    "\n",
    "# Преобразование текстов в последовательности\n",
    "new_sequences = tokenizer.texts_to_sequences(new_text_data)\n",
    "\n",
    "# Дополнение последовательностей до одинаковой длины\n",
    "pad_length = 200  # Должно совпадать с длиной, использованной при обучении\n",
    "padded_new = pad_sequences(new_sequences, maxlen=pad_length)\n",
    "\n",
    "# Применение модели к новым данным\n",
    "predictions = model.predict(padded_new)\n",
    "predicted_classes = np.argmax(predictions, axis=-1)\n",
    "\n",
    "# Если хотите преобразовать предсказанные классы обратно в названия\n",
    "predicted_job_titles = le.inverse_transform(predicted_classes)\n",
    "\n",
    "# Добавление предсказаний в DataFrame для вывода\n",
    "new_df['job_title'] = predicted_job_titles\n",
    "\n",
    "data_res = new_df\n",
    "# Сохранение результатов в новый файл\n",
    "#output_path = '/home/jupyter/datasphere/project/output_file2.csv'  # Укажите путь к выходному файлу\n",
    "#new_df.to_csv(output_path, index=False)\n",
    "#print(f\"Предсказания успешно сохранены в файл {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f2b0f2-aceb-49eb-9422-5034df8afcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install joblib catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800863de-c2f9-4b84-98eb-ee601662a754",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "import joblib\n",
    "\n",
    "def predict_salaries(input_csv_path, model_path, output_csv_path):\n",
    "    # Загрузка обученной модели\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "    # Загрузка данных из CSV файла\n",
    "    data = pd.read_csv(input_csv_path, low_memory=False)\n",
    "    data = data.fillna(\"\")\n",
    "\n",
    "    # Отбор нужных столбцов\n",
    "    data = data[['id', 'academic_degree', 'accommodation_capability', 'additional_requirements',\n",
    "                 'busy_type', 'career_perspective', 'education', 'education_speciality', \n",
    "                 'is_mobility_program', 'need_medcard', 'other_vacancy_benefit', \n",
    "                 'position_requirements', 'position_responsibilities', 'regionName', \n",
    "                 'regionNameTerm', 'company_business_size', 'required_certificates', \n",
    "                 'required_drive_license', 'required_experience',  'schedule_type', 'professionalSphereName', \n",
    "                 'languageKnowledge', 'hardSkills', 'softSkills']]\n",
    "\n",
    "    # Удаляем ненужные столбцы для предсказания\n",
    "    useless_columns = ['id', 'salary']  # Убедитесь, что 'salary' удален, если он уже есть\n",
    "    X = data.drop(columns=useless_columns, errors='ignore')\n",
    "\n",
    "    # Определяем категориальные признаки\n",
    "    categorical_features = [col for col in X.columns if X[col].dtype == 'object']\n",
    "\n",
    "    # Обработка категориальных данных\n",
    "    for feature in categorical_features:\n",
    "        X[feature] = X[feature].astype(str).fillna('missing')\n",
    "\n",
    "    # Преобразуем все числовые колонки в числовой формат, заменяя пропуски\n",
    "    for col in X.columns:\n",
    "        if col not in categorical_features:\n",
    "            X[col] = pd.to_numeric(X[col], errors='coerce').fillna(-1)\n",
    "\n",
    "    # Предсказание заработной платы\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    # Добавляем предсказанные значения в новый столбец \"salary\"\n",
    "    data['salary'] = y_pred\n",
    "\n",
    "    # Сохранение обновленного набора данных в новый CSV файл\n",
    "    #data.to_csv(output_csv_path, index=False)\n",
    "    return data\n",
    "\n",
    "data_sal = predict_salaries(\"TEST_SAL.csv\", \"catboost_model.joblib\", \"sample_sumbision.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990f66a1-c581-4a1d-9cee-7ec37e76abde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Приведение столбца 'salary' к целочисленному типу в df1\n",
    "data_sal['salary'] = data_sal['salary'].astype(int)\n",
    "\n",
    "# Добавление колонки task_type к каждому DataFrame\n",
    "data_res['task_type'] = 'RES'\n",
    "data_sal['task_type'] = 'SAL'\n",
    "\n",
    "# Объединение DataFrames\n",
    "submission = pd.concat([data_res, data_sal])\n",
    "\n",
    "# Выбор нужных колонок и сохранение результата\n",
    "result = submission[['id', 'job_title', 'task_type', 'salary']]\n",
    "result.to_csv('submission/submission_fin.csv', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
